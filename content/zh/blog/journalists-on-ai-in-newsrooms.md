---
# 文章标题 (根据内容生成/修改)
title: "AI浪潮下的新闻业：记者们的真实经验与思考"
# 文章发布日期和时间 (必填 - 使用 Obsidian 模板自动填充当前时间)
# 格式：YYYY-MM-DDTHH:MM:SS+时区偏移 (例如 +08:00 代表中国标准时间)
date: 2025-05-20T23:25:58+08:00
# 文章 SEO 描述 (推荐填写，用于搜索引擎和社交媒体预览)
description: "汇集多位记者、编辑的真实声音，探讨AI在新闻业的应用、挑战与伦理困境，展现从业者在智能浪潮下的复杂应对与深刻思考。"
# 文章列表页摘要 (推荐填写，用于博客列表页显示，覆盖 <!--more-->)
# 如果留空，Hugo 会使用 <!--more--> 分隔符或自动截取前 70 个词
summary: "《哥伦比亚新闻评论》汇集多位新闻从业者的视角，分享他们在AI时代使用AI的真实经验与思考。文章展现了AI在新闻编辑室中的多样化应用，从提高效率到辅助特定任务，同时也深入探讨了从业者普遍存在的对AI准确性、伦理、信任、工作替代及环境成本的担忧。这篇访谈集呈现了新闻业在AI浪潮下的复杂图景：既有实验探索，也有深刻警惕，强调了AI应作为辅助工具，而非取代人类判断和核心写作。"
# 草稿状态 (必填)
# 设置为 false 表示发布，设置为 true 表示为草稿
draft: false
# --- 可选字段 ---
# 文章作者
author: Mike Ananny 、Matt Pearce
# 文章分类
categories:
 - "人工智能"
 - "新闻业"
# 文章标签
tags:
 - "AI与新闻"
 - "记者视角"
 - "媒体伦理"
 - "人机协作"
 - "新闻未来"
---



**太长不看版（TL;DR）：**

这篇由《哥伦比亚新闻评论》发布的文章，汇集了多位来自不同媒体的记者、编辑和行业人士，分享他们在使用AI方面的经验、感受和思考。

AI已进入新闻编辑室，但从业者的态度和用法各不相同。有人用AI提高效率（转录、研究、辅助编程），有人用于特定任务（视觉分析、数据处理、[翻译](app://obsidian.md/copilot-custom-prompts/%E7%BF%BB%E8%AF%91.md)🔗）。但普遍存在对AI准确性、伦理、信任、工作替代及环境成本的担忧。许多人强调AI应是辅助工具，不能取代人类判断和核心写作。文章展现了新闻业在AI浪潮下的复杂应对：既有实验探索，也有深刻警惕。想了解更多细节，请阅读全文。


![Illustration by Anna Higgie](https://www.cjr.org/wp-content/uploads/2025/05/Columbia-AI-Chat-scaled.jpg)
Illustration by Anna Higgie

近年来，我们听闻了生成式AI（GenAI）生成错误百出的新闻报道、出版商起诉科技巨头抓取其新闻数据以保护自身权益、新闻编辑室制定GenAI使用指南，以及关于GenAI可能如何重塑报道方式的宏大预测。但所有这些感觉都与记者们在日常工作中实际应对GenAI的方式相去甚远。

在《哥伦比亚新闻评论》（CJR）与南加州大学 [AI for Media and Storytelling Initiative](https://www.uscaims.org/) 的合作项目中，我们向新闻行业的记者、编辑、高管及其他人士提出了一个多样化的问题：你的工作如何涉及AI，无论是好是坏？AI何时重要，它如何让你看待你的手艺、身份或职业未来？你何时欢迎AI进入你的工作，何时又保护你的工作不受其影响？

Reuters 新闻应用部门的创始人 Ben Welsh 表示：“大型语言模型（LLMs）简直提供了颠覆性的机遇。” 他所在部门约四分之一的代码现在由AI编写。报道科技世界的 *404 Media* 联合创始人 Jason Koebler 则认为：“倾向于这个未来，并与那些想要取代我们的公司结盟是不明智的，所以我们没有这样做。” *Washington Post* 视觉取证团队的创始成员 Sarah Cahlan 指出：“我们使用AI来检测卫星图像中的装甲车，并估算数百个视频中的人数。” 数据记者 Tristan Lee 观察到，AI“只会让一切变得稍微糟糕一些”。

记者们也将AI视为他们与受众关系的一部分。*VentureBeat* 的高级AI记者 Emilia David 说：“我希望我的读者知道，我不仅仅是在罗列事实，而是在帮助他们做出明智的决定。” *CalMatters* 和 *The Markup* 的首席影响力官 Sisi Wei 提到了AI对水资源使用、能源消耗和环境种族主义的影响：“每当我使用AI时，我都会想到环境成本。” WBEZ Chicago 的 Araceli Gómez-Aldana 则评论了AI的语言翻译能力，认为这是连接受众的新方式，让她更接近“帮助我的社区了解情况”的梦想，成为一名“双语记者”。

这些回答显示了AI如何重塑新闻行业。许多记者对这项技术持开放态度，但对其局限性表示怀疑。另一些人则从受众、真相、民主和气候危机等重大问题来看待AI新闻业。所有人都正在深思熟虑地应对这项技术对其工作、行业和职业道德的影响力。


## 不实验，毋宁死

###### Gina Chua
Executive editor of _Semafor_

在个人层面，我正在实验LLMs，看看生成式AI进步了多少，并测试这些工具如何在新闻语境中使用——例如，作为一种信息分类方式，比如 [可能的仇恨犯罪报告](https://www.semafor.com/article/02/18/2024/can-ai-count-hate-crimes__;!!LIr3w8kk_Xxm!ohk9HBxZL-S6mB_NTW2OJncFrEK-N9l0Pou-pfTyqn6s2wowhO9p_hjHwCcMqwo_2leHuaoxxiMk0xEirA$)，或者以 [更具对话性的方式](https://www.semafor.com/article/12/19/2023/how-ai-could-help-journalism-with-less-data__;!!LIr3w8kk_Xxm!ohk9HBxZL-S6mB_NTW2OJncFrEK-N9l0Pou-pfTyqn6s2wowhO9p_hjHwCcMqwo_2leHuaoxxiM-WshHrw$) 呈现新闻。我也在尝试构建一个系统，比较不同新闻编辑室如何报道同一事件——他们在哪些事实上有共识，哪些细节是某些媒体独有的，以及他们为报道带来了哪些视角。

在 *Semafor*，我正与同事们合作构建工具，这些工具要么简化我们的工作流程——例如校对机器人，要么扩展我们的能力，比如改进的搜索工具，可以帮助我们找到特定主题的相关报道。作为一家年轻的公司，我们在技术和工作流程方面都有实验空间，这令人兴奋。

在行业层面，我参与了关于生成式AI可能如何颠覆信息生态系统的讨论。我们已经可以看到它正在改变搜索、研究和写作；它将如何进一步革新人们寻找、消费和参与新闻的方式？理解这些变化并保持领先，可能是我们面临的最关键挑战之一。

## 将AI视为一个聪明但爱胡扯的助手

![Anna Higgie](https://www.cjr.org/wp-content/uploads/2025/05/Columbia-Portrait-2-Nicholas-scaled.jpg)


###### Nicholas Thompson
CEO of _The Atlantic_

我正在写一本关于跑步的书，我使用AI的方式就像使用一个速度极快、阅读量惊人、异常聪明但写作糟糕且经常胡扯的研究助手。我会上传我的书稿部分内容以及采访记录，询问我写的一切是否与我的消息来源一致。我会让它阅读长篇文本，并标记任何未按时间顺序引入的材料。我会让它检查章节中的所有论断是否逻辑一致。所有这些都在我输入一个详细描述我想要写的那种书风格的长提示后进行。要求越具体，提示越复杂，答案就越好。它远不如真正的编辑有用，但仍然相当不错。不过，我绝不会让它写任何东西。这似乎是不道德和愚蠢的——而且可能导致失去版权。

## AI是为了提高效率，而不是写作

###### Emilia David
*VentureBeat 的资深 AI 记者，撰写有关 AI 应用、代理、模型和监管的文章*


我从2016年开始写关于AI的文章，当时主要称之为机器学习，除了期望它能比我更快地转录采访外，我并不认为它对我的工作会有多大用处。快进到今天，我刚刚用OpenAI的o3-mini将一篇研究论文喂给了ChatGPT。我要求它提供摘要，让ChatGPT给出三个潜在的标题，并向它提问，这些问题如果我自己找答案可能需要一个小时。我有一个定制的GPT，我对其进行了微调，使其像 *VentureBeat* 的读者一样回应，我用它来完善报道想法。我使用MidJourney为我的报道生成配图。在报道一个大型专题时，我使用Google的NotebookLM来组织我的文件。我最喜欢的是使用定制的GPT来为我过度使用的词语提供同义词。

AI聊天机器人、应用程序和功能已经变得如此普遍，即使我在工作时完全不想接触AI，那也是不可能的。与此同时，我对其他人使用AI变得更加怀疑。我预计许多报道提案都是由聊天机器人撰写的。当我寻找社交媒体回应以添加到综述报道中时，我从不确定它们是否由人类撰写。

尽管我相信AI有助于提高我的效率，但我拒绝将其用于写作。写作很困难，也是我最不喜欢的任务，但我不想让AI替我写作，无论我写的一些新闻多么程式化。我希望我的读者知道，我不仅仅是在罗列事实，而是在帮助他们做出明智的决定。如果我让AI模型替我写作，我觉得我剥夺了与读者关系中重要的一部分。我相信，阅读财报报道或体育赛事新闻（有时使用AI工具撰写）的人们，值得获得由更了解人们为何需要了解这些特定新闻的人类来传递新闻的尊重。人类记者为他们的人类读者带来新闻报道的背景信息。当然，AI模型可以近似做到这一点，但人们应该从其他人那里听到新闻。

## AI本身只是个花招

###### Zach Seward
*《纽约时报》AI 项目编辑主任*

我得坦白一件事。作为工作中的“AI达人”，人们常常认为，在我的个人生活中，我肯定会使用各种聊天机器人、代理、数字助手等来自动化我生活的方方面面。当然，我确实会尝试每一个新的AI应用和功能。但事实是，我能说出证明有价值并再次使用的，不超过一两个。

这并不是说我是AI怀疑论者。在工作中，[我们经常使用](https://www.zachseward.com/my-panel-at-web-summit-about-how-the-times-uses-ai/) 这项技术进行调查、改进工作流程以及探索体验 *Times* 的新方式。AI帮助我们调查 Pete Hegseth 的饮酒习惯，[追踪政府网站的变化](https://www.nytimes.com/interactive/2025/03/07/us/trump-federal-agencies-websites-words-dei.html)，以及 [许多其他](https://www.nytimes.com/by/dylan-freedman) 近期报道。当与传统报道和编码专业知识结合时，它是一个强大的工具。

但这，我认为，解释了这种脱节。AI本身只是个花招。像所有软件一样，当与结构良好的数据和知道如何操作的人结合时，它才有用。我们对代理未来的愿景有一天可能会成为现实，但现在我看到的是许多无法工作的消费者应用，只存在于广告中的功能，以及我只会在不经意间触发的助手。

## 利用AI增强人类优势
![Anna Higgie](https://www.cjr.org/wp-content/uploads/2025/05/Columbia-Portrait-1-Millie-Tran-version-2-scaled.jpg)

###### Millie Tran
*外交关系委员会首席数字内容官*

目前，人们大多将AI视为提高效率的方式。但我们如何创造新闻、商业模式、用户体验和信息生态系统的根本性转变才刚刚开始。在 Council on Foreign Relations——一个无党派、独立的智库、会员组织和出版商——我们大多仍在提问：在这个新格局下，我们如何将专业知识产品化？当我们被分析淹没时，我们工作的价值是什么？这可能会如何改变人们对复杂国际问题的理解？

我付费使用了 Claude，并实验了OpenAI的Deep Research和Google的NotebookLM。我最近迷上了 Granola，它让我重新思考一个真正好的AI辅助笔记工具能做什么。但我仍然只是触及表面。感觉它只是在我目前工作之上的一层。AI尚未从根本上改变我的工作方式——至少目前还没有。

我在两个植根于手艺的历史类比中找到了慰藉。相机发明时，画家们担心失业。但印象派应运而生——一种相机无法复制的新绘画形式。摄影将画家从写实主义中解放出来，让他们能够专注于使用相机无法捕捉的可见笔触和技巧来表达主观体验。今天，我们应该关注AI能将我们从什么中解放出来，以及我们如何利用人类独有的优势。当刺绣从手工转向机器生产时，机器更快，并且可以持续地完成更复杂的图案。但随着机器刺绣的普及，手工作品获得了新的文化和经济价值。今天，我们应该思考随着供应的激增，某些类型新闻的价值将如何变化和演变。

## 使用AI——但不能作为唯一来源

###### Sarah Cahlan
*普利策奖获奖记者兼《华盛顿邮报》视觉取证团队创始成员*


当我们的视觉取证团队深入调查时，我们会收集、验证和分析尽可能多的信息：视频、照片、地图和文件，以构建3D模型、视觉同步和表格。这项工作非常耗时，而我们希望快速行动。我们使用AI来检测 [卫星图像中的装甲车](https://www.washingtonpost.com/world/2024/03/19/gaza-journalists-killed-israel-al-jazeera-footage/)，并 [估算数百个视频中的人数](https://www.washingtonpost.com/investigations/2021/01/16/video-timeline-capitol-siege/)。尽管AI缩短了报道时间，甚至帮助我们发现了新的线索，但如果我们的唯一来源是AI，我们将不会发布报道——它不能替代记者细致的审查。

## 与人类结盟，而非科技公司

###### Jason Koebler
*404 Media 的联合创始人*

在 *404 Media*，一家记者拥有的科技出版物，我专注于人们如何使用AI及其影响。我整天都在深入凝视AI生成的深渊。AI已经深刻地改变了我们的行业，催生了 [立即抄袭我们作品](https://www.404media.co/why-404-media-needs-your-email-address/) 的内容农场，[用垃圾信息淹没互联网](https://www.404media.co/where-facebooks-ai-slop-comes-from/) 的模型，以及 [允许自己解雇大量写手](https://futurism.com/the-byte/media-publisher-replaces-jobs-ai) 并幻想AI效率能提高幸存者生产力的新闻高管。

我认为，倾向于这个未来，并与那些想要取代我们的公司结盟是不明智的，所以我们没有这样做。在 *404 Media*，我们向读者展示我们是具有视角的活生生的人。当许多新闻行业为了算法优化、向LLM公司出售内容访问权、[让AI与自己的专栏作家争论](https://www.cnn.com/2025/03/05/media/la-times-ai-kkk-comments/index.html)、推广 [让公众“提问”](https://www.washingtonpost.com/pr/2024/11/07/washington-post-launches-ask-post-ai-new-search-experience/) 文章的无谓聊天机器人，或推动记者 [将AI工具整合到写作流程中](https://www.theverge.com/news/613989/new-york-times-internal-ai-tools-echo) 时，我们通过说：“嘿，没人想要这个！”来脱颖而出。

我们并非鸵鸟。我们每天都使用AI工具来了解它们如何工作、它们的局限性，以及最重要的是，它们如何被利用成为互联网上主导的内容类型。正因为如此，我们在生成式AI方面拥有一些领先的报道。AI不会消失，如果它变得更值得信赖，或许如果推动它的公司找到更道德的商业模式，我可能会在未来使用它。我曾尝试使用AI来撰写复杂的《信息自由法案》（FOIA）请求和FOIA上诉，以及解析大型文件，尽管结果并未令我满意。我被动地使用AI形式来帮助转录采访，获取外语YouTube视频的大意，以及编辑短视频和播客。语言翻译和转录感觉像是真正的游戏规则改变者，而其他AI工具感觉像是垃圾信息制造机。我会使用AI来帮助寻找新信息，但不会用来写我的文字。

## 不要让AI损害记者信任

![Anna Higgie](https://www.cjr.org/wp-content/uploads/2025/05/Columbia-Portrait-4-Khari-scaled.jpg)

###### Khari Johnson
*CalMatters 的科技记者，同时是弗吉尼亚大学 Karsh 数字民主研究所的实践研究员，报道人工智能领域已有十年经验*

我不在写作中使用AI。未来我可能会用它来更好地组织段落，但除此之外的任何用途都会引发伦理问题，并威胁到我的表达能力和言论自由。我认为所有写作者都应该警惕放弃这些人类独有的能力。我也质疑使用AI写作如何威胁记者与读者之间的信任。报道上署名的是我，而不是一个既是写作机器又是能言善辩的骗子。就像一些监管机构认为 [当AI在个人生活中做出关键决定时，人们应该获得披露](https://calmatters.org/economy/technology/2025/03/ai-regulation-after-trump-election/) 一样，读者也应该知道记者在写作过程中是否使用了大型语言模型。

在我的报道中，我主要使用AI进行转录，尽管我总是会回听采访以确保AI没有听错任何词。我也使用 [Digital Democracy](https://digitaldemocracy.calmatters.org/)，这是由 *CalMatters* 主导的一项倡议，它为公众和记者提供公共听证会和法案草案的可搜索转录。我也开始使用AI Tip Sheets，它分析关于立法者、倡导者和游说者的数据，向记者发送报道线索。它 [目前对加州的记者开放](https://forms.gle/pe2Nt1SnVY5qENap6)，今年晚些时候可能会扩展到其他州。

我最喜欢寻找在新闻业中实际使用AI方法的地方之一是 [Pulitzer Center AI Accountability initiative](https://pulitzercenter.org/focus-areas/information-and-artificial-intelligence/ai-spotlight-series#resources)。它包含了来自世界各地的建设性、有影响力的见解，例如记者如何调查 [印度拒绝向人们提供食物的算法](https://pulitzercenter.org/how-we-investigated-welfare-algorithms-india-part-i)，或者 Associated Press 记者如何仔细查阅记录请求、政府合同和法院文件，以 [评估AI的全球影响](https://pulitzercenter.org/blog/tracked-how-ap-investigated-global-impacts-ai)。[2024年普利策奖决赛入围者中约有10%](https://www.niemanlab.org/2024/05/for-the-first-time-two-pulitzer-winners-disclosed-using-ai-in-their-reporting/) 在报道中使用了AI，这一事实清楚地表明 [这项技术可以为读者和社会带来成果](https://huggingface.co/posts/fdaudens/982146976081521)。但透明度——谁使用以及如何使用——可以帮助记者报道AI，保留我们的人性，并确保AI不会无意中损害记者与读者之间的信任。

## AI正在蚕食我们的行业，并削弱我们的技艺。拒绝它

###### Brian Merchant
*《Blood in the Machine》一书的作者，该书及同名通讯聚焦于人工智能与劳动关系，此外还曾担任《洛杉矶时报》的科技专栏作家*

作为一名科技写作者，我觉得有责任使用AI来理解其影响。作为一名记者，我觉得有责任完全不使用AI。

当OpenAI发布新模型时，我会进行实验。我对它生成的结果、系统产生的内容以及它是否侵犯版权作品或复制偏见感兴趣。几周前 [Studio Ghibli 风格AI图像热潮](https://www.404media.co/hayao-miyazaki-who-said-ai-is-insult-to-life-itself-reduced-to-ai-generated-meme-by-openai/) 之后，我试探了图像生成模型，看看ChatGPT是否对允许你“吉卜力化”的内容有限制。限制很少。

当考虑在新闻实践中使用AI时，我认为问自己这个问题很有帮助：我会自动化我工作中的某个部分吗？对某些人来说，答案可能是肯定的：一些记者可能会自动化导语的修改或标题创意的头脑风暴。这是可以辩护的，尽管我担心这会导致 [认知卸载](https://www.mdpi.com/2075-4698/15/1/6) 并削弱我们的技能。我决定我需要努力思考我的标题，思考我为什么要进行修改。AI系统太不可靠，它们的偏见隐藏得太深，无法用于任何形式的报道。我见过有写作者引用Google Overview作为来源。这是不可辩护的。

作为记者，我们需要考虑我们领域的健康状况。主要的AI模型未经同意就用我们的作品进行训练，它们正在削弱人类新闻业的市场。很少有媒体公司CEO会说“我们要用AI取代你们的同事”，但看看在人类劳动力流失后，AI是如何被承诺增加价值的：[*BuzzFeed* 在解雇其新闻部门后宣布推出AI问答](https://www.hollywoodreporter.com/business/business-news/buzzfeed-ai-creators-news-shut-down-1235483607/)。我以前工作的报纸 *LA Times* 在近年来解雇了一百多名员工后，增加了“AI Insights”功能。新闻业正在急剧衰退。AI，就像数字视频和之前科技巨头强加给我们行业的许多前景一样，被提供给我们作为最新的救命稻草。但除非像Google和OpenAI这样的AI公司愿意与记者——以及所有其他创作者和工作者——就合作条款进行谈判，否则我们有责任彻底拒绝AI。

## AI会说多种语言，但仍需要人类翻译

![image.png](https://pic.huangzuomin.com/20250520231309446.png)




###### Araceli Gómez-Aldana
*芝加哥 WBEZ 的新闻记者兼主播，2023 年斯坦福大学 John S. Knight 新闻奖学金的获奖者*

当我开始对新闻业感兴趣时，我一直在想我会使用哪种语言。我在一个说西班牙语的家庭中双语长大，与父母和祖父母说西班牙语。我学会了用西班牙语读写，但我的主导语言变成了英语。我梦想成为一名双语记者。但由于缺乏时间、资源或西班牙语编辑，将我的作品翻译成西班牙语很困难。将我所有作品翻译成西班牙语的目标变得不切实际。困扰我的是，我能提供给西班牙语社区和我的父母的，只有用英语发表的新闻报道。

当我在 Stanford 的 John S. Knight Journalism Fellowship 项目中学习大型语言模型时，我对它们生成类人翻译的能力感到兴奋。尽管LLMs不是知识的生产者，但它们确实能生成类人语言。LLMs可以翻译一些常见语言的文本，包括英语、西班牙语、法语、德语、中文和日语。

但并非所有语言都能产生高质量的结果。我逐渐意识到，这些模型尚不能翻译新闻报道。我有几个主要担忧：新闻报道翻译的准确性、文化理解、引文的语气和理解翻译——不仅仅是字面逐字翻译——以及适应各种方言和识字水平。人类记者和编辑对于生成高质量翻译仍然至关重要。

最终，我希望LLMs能被用作工具，帮助解决许多社区面临的现有语言障碍。我想为帮助我的社区了解情况做出贡献。我认为很快就能通过使用LLMs翻译多种语言的新闻报道来实现这一点，我期待着在我的署名中加上“双语记者”。

## 不要被AI垃圾信息的浪潮压垮

###### Tristan Lee
*数据科学家和研究员，曾为 Bellingcat 和《德克萨斯观察家》调查极右翼势力*

我经常收到的一个问题是：“AI如何改变视觉调查？”我的标准答案是：并没有真正改变，它只是让一切变得稍微糟糕一些。[AI垃圾信息的浪潮](https://www.404media.co/ai-slop-is-a-brute-force-attack-on-the-algorithms-that-control-reality/) 正在淹没互联网的几乎每个角落，而我大部分工作时间都在互联网上度过。虽然当前这批生成式AI工具确实提高了一些生产力，但它们带来的负面后果远大于此。

很大一部分“OSINT”（开源情报）和编程工作包括 [正确地使用Google搜索](https://osintteam.blog/isnt-osint-just-glorified-googling-4f79e3f32d8e)，但基于AI的SEO垃圾信息 [让每个搜索引擎都变得更糟](https://link.springer.com/chapter/10.1007/978-3-031-56063-7_4)。Reddit 则在 [引用](https://www.techtarget.com/whatis/feature/Reddit-pricing-API-charge-explained) 科技公司抓取其内容训练LLMs的滥用行为后，严重限制了其API。这使得研究Reddit变得更加困难，而Reddit之前开放的数据曾被研究人员用来理解在线 [回声室](https://www.nature.com/articles/s41598-020-73510-5) 和 [有毒社区](https://www.tandfonline.com/doi/abs/10.1080/0735648X.2022.2074867)。

视觉调查最明显的挑战是声称来自冲突或抗议的虚假图像或视频，这些通常被 [BBC Verify 的 Shayan Sardarizadeh](https://reutersinstitute.politics.ox.ac.uk/news/bbc-expert-debunking-israel-hamas-war-visuals-volume-misinformation-twitter-was-beyond) 揭穿。生成的图像仍然具有明显的特征（纹理、光照、细节），生成的视频要避免被检测到还有很长的路要走。但这并不能阻止虚假信息病毒式传播。更常见的是，将来自一场冲突的视频 [误传为来自另一场冲突](https://www.reuters.com/fact-check/syria-hospital-attack-footage-falsely-said-be-gaza-2023-2023-11-08/)，或者将视频游戏中的画面 [冒充为真实画面](https://www.reuters.com/article/fact-check/video-shows-arma-3-game-not-russian-and-ukrainian-planes-idUSL1N3A91K8/)。

我偶尔使用ChatGPT，主要是为了生成一段我不熟悉的编程语言代码片段，或者使用一个有很多复杂选项的命令行工具。当我需要识别近万张图片中包含纳粹标志的图片时，我快速创建了一个Web应用，让我可以批量分类它们。考虑到我在前端Web开发方面的经验不足，如果没有生成工具，开发这个Web应用（它本身就节省了我几个小时的手工工作）会花费更长时间。这类任务通常需要多次迭代才能正确，而且生成的代码质量通常很差。但它们可以完成工作。

## 要知道，在一些新闻编辑室，LLMs已经改变了游戏规则

###### Ben Welsh
*路透社新闻应用部门的创始人，负责领导仪表板、数据库和其他自动化系统的开发*

新闻编辑室是工厂。但我们的产品不是用钢铁、铝或玉米制造的。它们是用信息制造的。我的车间位于纽约时代广场，我在那里领导一个专门的 Reuters 团队，专注于为我们的通讯社客户、通过LSEG终端获取商业新闻的投资者以及光顾 reuters.com 的任何人发布数据产品。像任何工厂一样，自动化是我们的核心方法。利用我们作为记者、编辑和程序员的技能，我们每周发布数百个突发新闻图表，无需人工干预。我们设置软件来为我们赶上截止日期。大型语言模型已经在加速我们的工作。每天，集成到我们编码工具中的新一代数字助手都会建议下一步输入什么，并标记我们的错误。

如果我们严格控制并审查AI的建议，这种神奇的自动完成形式可以提高我们编码的速度和质量。Google CEO Sundar Pichai 最近宣布，AI现在生成了他公司四分之一的代码。我相信我的团队也能达到同样的水平。

十年前，像我们这样的数据记者竞相掌握基于与大型语言模型相同原理的早期技术。不幸的是，它们需要大量的人工训练和编程专业知识才能执行，而且结果并不令人印象深刻。这些2010年代的工具现在看起来就像算盘一样过时。大型语言模型简直提供了颠覆性的机遇。它们无需编码专业知识或训练即可完成与老式工具相同的任务。通过从网络抓取的大量信息进行训练，它们通常可以产生更好的结果。

要亲身体验这种新力量，请学习我最近与 University of Maryland 的数据新闻教师 Derek Willis 共同开发的免费开源教科书。我们展示了记者如何利用大型语言模型在政治竞选产生的数据干草堆中找到腐败的针。这些技术已经在改变 Reuters 记者收集新闻的方式，使更高级的机器学习更容易被更广泛的人群使用。我无法预测这一切将走向何方，但对我来说，这些工具终于适合我们的目的了。

## AI应该被视为一只手，而不是一个大脑

###### Susie Cagle
*为 ProPublica、《卫报》、Wired、《国家》及其他多家媒体服务的作家和艺术家*

在我还在截稿日期前弄坏笔尖的时候，我可能半心半意地希望有一台电脑能比我自己潦草地画得更好。我第一次学习绘画是在2008年，当时新闻业正经历从纸媒到数字化的颠覆性转变。我想给屏幕带来一种触感——提醒人们物理世界和人类的手。

那时我画得不好，也从未成为一名出色的插画家。构成我插画报道作品的 [连环画](https://www.themarshallproject.org/2023/10/24/california-corcoran-prison-climate-change-flood) [其效果](https://www.thenation.com/article/society/coronavirus-healthcare-consolidation/) [与其说是美](https://features.propublica.org/eminent-domain-and-the-wall/eminent-domain-comic-rio-grande-valley/)，不如说是概念和故事中逐格构建的叙事。每一幅画都是数百个决定的集合——画框的构图、主体脸上精确的表情、唤起精心考虑的情绪的调色板，所有这些都是在广泛的视觉研究后确定的。存在一个假设的未来，机器人可以在我设定的限制和规则内执行绘画任务——AI可以让我的工作更顺畅、更高效、更优化。但通过使其失去人性，它也会从根本上使其失去真实性。

如果AI被用作一只手，而不是一个大脑，我并不害怕。我的犹豫与其说是信任问题，不如说是愿景的根本冲突。我的插画作品在每一件作品中都坚持一种不可改变的“来自某个地方的视角”。每一条手绘线条都是对新闻业作为一种手艺的主观性的有目的的提醒。谁会选择为了千篇一律和速度而外包人性呢？

## 问问自己：这值得付出环境成本吗？

###### Sisi Wei
*在 CalMatters 和 The Markup 担任首席影响官*

我作为一名数据记者在这个行业成长，所以我习惯了人们对新工具或新技能既害怕又兴奋。我记得我曾希望每个记者都能学会编程，因为编程技能让我们能够亲自核实数据和来源。编程也帮助我构建了赋予人们超能力的工具——比如知道 [他们的医生收了哪些药厂的钱来推广药品](https://projects.propublica.org/docdollars/)，或者 [仔细审查任何美国非营利组织的税务申报](https://projects.propublica.org/nonprofits/)。

AI感觉就像同样的对话。但这一次，更多的人关心并有伦理担忧。最困扰我的是 [AI是能源消耗大户](https://calmatters.org/economy/technology/2025/01/artificial-intelligence-is-bringing-nuclear-power-back-from-the-dead-maybe-even-in-california/)。与ChatGPT进行一次简短对话 [消耗相当于一瓶16盎司水的能量](https://themarkup.org/hello-world/2023/04/15/the-secret-water-footprint-of-ai-technology)，与大型语言模型互动一次消耗的能量是普通Google搜索的 [三到十倍](https://www.latimes.com/environment/story/2024-08-26/tech-firms-conceal-water-and-power-demands-of-ai-computing)。为了给AI提供动力，科技公司正在建设新的数据中心，发电厂正在以 [不成比例地威胁黑人社区增加污染](https://capitalbnews.org/ai-data-centers-south-carolina-black-communities/) 的方式复活。每当我使用AI时，我都会想到环境成本。

我也知道AI可以成为一个令人难以置信的善用工具。例如，我们的 [Digital Democracy 项目](https://calmatters.digitaldemocracy.org/) 就是由AI驱动的。它追踪加州州议员的几乎所有可追踪信息，解析这些海量数据，然后为我们的记者生成报道线索。一些AI生成的线索，一个精通数据的政治记者可能需要几周甚至几个月才能找到，而我们AI辅助的报道 [已经在立法机构产生了影响](https://calmatters.org/inside-the-newsroom/2024/07/digital-democracy-impacts/)。

每当我使用AI时，我都会问它是否值得——然后我问自己：[我真的能知道这个问题的答案吗？](https://www.axios.com/2025/04/14/chatbots-chatgpt-ai-carbon-climate) 但仍有希望。研究人员正在 [提出解决方案](https://hbr.org/2024/07/the-uneven-distribution-of-ais-environmental-impacts) 来减轻AI的环境成本。我的一位数据工程师 [在本地运行LLMs](https://themarkup.org/hello-world/2024/09/07/how-im-trying-to-use-generative-ai-as-a-journalism-engineer-ethically)，以减少能源消耗。如果你使用AI，并且也有这些困扰，我很想听听你做了些什么。

## 捍卫新闻自由

###### Karen Rønde
*丹麦新闻出版集体管理组织（DPCMO）的首席执行官，代表丹麦新闻行业99%的成员*

在我的工作中，我试图为丹麦出版商和记者争取AI公司的公平待遇（报酬和数据），我面临许多问题和困境：我们的新闻机构是否应该出于商业原因、技术原因或民主原因与AI公司签订协议？

我们需要明智地使用AI。在欧洲，我们优先考虑数字韧性；数字主权；强大的信息生态系统；有韧性的选举过程；准备和就绪；一个 [民主盾牌](https://www.europarl.europa.eu/RegData/etudes/BRIE/2024/767153/EPRS_BRI$2024$767153_EN.pdf) 以对抗在线外国信息操纵和干预；以及人类尊严、自由、平等、团结、尊重人权和法治等普世价值。证据表明，行为者正在利用信息操纵和其他策略干预我们的民主和自由。

全球日益依赖少数AI产品和服务影响着新闻自由和媒体多元化。AI公司通过内容审核、审查、算法过滤和模型训练偏差来控制信息获取。AI工具塑造着新闻研究、事实核查，甚至写作方式，这可能与当地法律和文化规范不同。AI生成的内容或AI辅助的研究可能会强化其所有者的叙事和议题框架方式，导致全球新闻同质化。这可能会边缘化当地声音、语言和视角；挑战新闻自由；并特别影响丹麦这样一个小国家和语言区域。当地的丹麦媒体内容将我们联系在一起，挑战我们，让我们更聪明，娱乐我们，并将我们作为一个国家联系起来。

我们总是说，编辑媒体的多元化构建了信任和信息韧性。多样化的新闻内容提供了社会凝聚力和参与度。在AI时代，新闻提供者必须确保我们新闻的准确性和公正性——我们必须捍卫新闻自由和主权。

## 给予受众应得的

###### Claire Leibowicz
*非营利组织“人工智能伙伴关系”（PAI）的人工智能与媒体诚信项目负责人*

新闻编辑室同时在为威胁做准备（例如，通过 [对媒体进行加密认证以证明其真实性](https://c2pa.org/)），并拥抱AI作为降低成本、讲述故事，甚至与受众 [建立信任](https://partnershiponai.org/ai-for-newsrooms/) 并重新构想新闻的方式。有时这种拥抱看起来务实、基于证据，甚至具有革命性。有时，它看起来像是对新闻编辑室错失社交媒体时刻这一集体感觉的过度矫正——一种对行业商业模式困境的冲动性修复。

然而，新闻编辑室对受众需求的深刻敏感性一直令我印象深刻，即使这些需求尚未完全明确或统一。我合作过的 [新闻编辑室](https://partnershiponai.org/ai-for-newsrooms/) 一直在问：受众准备好了吗？我们欠他们什么？

我们在 Partnership on AI (PAI) 的 [BBC 和 CBC 案例研究](https://syntheticmedia.partnershiponai.org/#case_studies) 中探讨了这个问题，追溯他们如何决定使用AI生成媒体进行故事讲述，并实施 [PAI 关于负责任AI的指南](https://syntheticmedia.partnershiponai.org/)。[CBC 决定不使用AI来隐藏新闻来源的身份](https://partnershiponai.org/wp-content/uploads/2024/03/pai-synthetic-media-case-study-cbcnews.pdf)，称这项技术“远远超出了我们服务的大多数受众的理解能力”。相比之下，[BBC 在关于匿名戒酒会（Alcoholics Anonymous）的报道中使用了深度伪造技术来模糊受访者的面部](https://partnershiponai.org/wp-content/uploads/2024/03/pai-synthetic-media-case-study-bbc.pdf)，认为在适当披露的情况下，这项技术可以“使纪录片观众在观看受访者时不受传统匿名技术通常固有的偏见影响”。这两个组织都基于如何最好地服务于他们的受众来做出决定——无论AI带来什么挑战，这都是该领域应该追求的北极星。

## 依靠AI完成工作

###### Ina Fried
*Axios 的首席技术记者，同时也是每日《Axios AI+》通讯的作者*


我看到了AI帮助我和其他记者增强AI永远无法取代的技能——判断力和人性——的巨大潜力。

我过去常常避免录音采访，因为我从来没有时间听。但现在我使用 Otter，它可以录音并自动生成转录。结果可能不完美，但它们仍然是游戏规则改变者。AI帮助我更快地找到录音中的特定位置并查阅我的笔记，比我自己做快得多。我也使用AI研究我报道的人物和公司。我一直优先准备采访，现在AI帮助我做公关人员通常对我进行的背景简报。我使用过的工具包括OpenAI、Google和Perplexity，新工具不断涌现，比如中国的 Manus AI。我可以设想其他使用AI的方式，比如用于标题写作和搜索引擎优化。另一种情况是使用AI进行更多数据密集型项目，检查大型数据集并提出值得报道的模式。记者仍然需要判断AI“趋势”是否真正具有新闻价值，是一个可解释的波动，还是仅仅一个异常。

*Axios*，像许多媒体一样，仍在评估如何最好地使用这项新技术。我们最近与OpenAI签署了一项协议，使我们的新闻编辑室能够访问企业版ChatGPT。（*Axios* 和 OpenAI 有一项许可和技术协议，允许OpenAI访问 *Axios* 部分故事档案，同时帮助资助 *Axios* 在四个地方城市启动，并提供一些AI工具。*Axios* 拥有编辑独立性。）我们目前不使用ChatGPT或其他生成式AI来创建用于发布的内​​容，除非目的是展示该技术能做什么或不能做什么。这必须明确区分。我们也鼓励新闻编辑室员工实验这些工具，看看它们如何改进人类创作的内容。

## 使用内容凭证

###### David Carson
*斯坦福大学约翰·S·奈特新闻学研究员，目前从《圣路易斯邮报》的专职摄影记者职务休假中*

在我三十多年的摄影记者生涯中，我是数字摄影的早期采用者，自学了如何拍摄/编辑视频，并成为一名持证无人机飞行员。我对AI既警惕又着迷。一些AI对摄影新闻业无疑是积极的。相机中的AI人脸和物体识别系统提高了体育、野生动物和肖像摄影的跟踪和对焦准确性。AI可以将音频转录，帮助编辑快速找到埋藏在数小时素材中的声音片段。许多摄影师可以使用 Grammarly 来减少字幕中的错别字和错误。我担心生成式AI对摄影新闻业的潜在危害，因为所有逼真的AI生成图像都是谎言。AI显著降低了生成大量模糊现实界限的虚假信息和不实信息所需的技能。飓风 Helene 后一个小女孩坐在船上抱着小狗的逼真AI图像，今年洛杉矶火灾期间好莱坞标志周围火焰的AI图像，以及 JD Vance 诽谤 Elon Musk 的伪造音频，这些都在社交媒体上广泛传播，是公众被欺骗的例子。

许多新闻机构限制在新闻报道中使用AI生成图像。新闻行业可以更进一步，在新闻照片、视频和音频上使用所谓的内容凭证，提供关于内容的来源、历史和编辑信息。可以将内容凭证想象成你在杂货店看到的食品营养标签。内容凭证使用开放源代码的 Coalition for Content Provenance and Authenticity (C2PA) 标准，该标准由科技公司、媒体组织和硬件制造商合作开发，可以添加到真实新闻照片和AI生成图像中。OpenAI 的 DALL-E 图像生成器已经开始为其生成的图像添加内容凭证。AP、Getty、Reuters、AFP 等机构一直在测试符合C2PA标准的相机。预计C2PA今年将被采纳为ISO国际标准。实施需要努力。但希望公众很快能从C2PA标准的广泛采用中受益，目标是建立新闻行业的信任和透明度。

原文链接：https://www.cjr.org/feature-2/how-were-using-ai-tech-gina-chua-nicholas-thompson-emilia-david-zach-seward-millie-tran.php
